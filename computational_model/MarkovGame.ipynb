{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2b68f8c4",
      "metadata": {},
      "source": [
        "# Part 1: State Value Function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3289f55",
      "metadata": {
        "id": "d3289f55"
      },
      "source": [
        "Import Libaries and Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "628efc5d",
      "metadata": {
        "id": "628efc5d"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from memo import memo\n",
        "from functools import cache\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d2362d2",
      "metadata": {
        "id": "7d2362d2"
      },
      "source": [
        "Magic Numbers for Roles, Actions, and Intents \\\n",
        "Lists containing roles, actions \\\n",
        "All possible role combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "92284704",
      "metadata": {
        "id": "92284704"
      },
      "outputs": [],
      "source": [
        "ATTACKER = 0\n",
        "DEFENDER = 1\n",
        "HEALER = 2\n",
        "\n",
        "ATTACK = 0\n",
        "DEFEND = 1\n",
        "HEAL = 2\n",
        "\n",
        "ENEMY_NO_ATTACK_INTENT = 0\n",
        "ENEMY_ATTACK_INTENT = 1\n",
        "\n",
        "ROLES   = [ATTACKER, DEFENDER, HEALER]\n",
        "ACTIONS = [ATTACK, DEFEND, HEAL]\n",
        "\n",
        "ROLE_COMBOS = list(product(ROLES, repeat=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d218a9",
      "metadata": {
        "id": "18d218a9"
      },
      "source": [
        "Define environment parameters\n",
        "* Max Team HP (also assumed to be team init HP)\n",
        "* Max Enemy HP (also assumed to be enemy init HP)\n",
        "* Players and their stats\n",
        "* Role assignment under consideration\n",
        "* boss damage\n",
        "* enemy's attack probability in every round\n",
        "* epsilon, randomness in action\n",
        "* time horizon for Markov Game simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "077c511c",
      "metadata": {
        "id": "077c511c"
      },
      "outputs": [],
      "source": [
        "TeamMaxHP       = 10\n",
        "EnemyMaxHP      = 31\n",
        "\n",
        "player_stats    = jnp.array([\n",
        "    [2,2,2],        # Player 1 stats: [Attack, Defense, Healing]\n",
        "    [2,2,2],        # Player 2 stats: [Attack, Defense, Healing]\n",
        "    [2,2,2],        # Player 3 stats: [Attack, Defense, Healing]\n",
        "])\n",
        "\n",
        "role_assignment = [ATTACKER, ATTACKER, ATTACKER]\n",
        "boss_damage = 2\n",
        "EnemyAttackProb = 1.0\n",
        "\n",
        "EPSILON = 1e-10       # action randomness\n",
        "HORIZON = 10        # simulation steps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc538128",
      "metadata": {
        "id": "bc538128"
      },
      "source": [
        "Markov Game Formalization of the Game\n",
        "\n",
        "* $H_t \\in \\{0, ..., 10\\}$,           team HP\n",
        "* $H_e \\in \\{0, ..., 10\\}$,           enemy HP\n",
        "* $i \\in \\{0,1\\}$,                    enemy's attacking intent at a given round (1 for \"will attack\", 0 otherwise).\n",
        "* $S = i \\times H_t \\times H_e$,             all possible intent and HP combinations\n",
        "* $A = Actions^3$, Actions = {Attack, Defend, Heal}\n",
        "* $T: S \\times A \\rightarrow S$,             Transition function\n",
        "* $R: S \\rightarrow \\mathbb{R}$,    State reward function, $100 \\times (1 - T/H)$ for dead enemy, alive team. $T$ is the number of turns it took to beat the enemy; else, 0\n",
        "* role-specific policies $\\pi(a|s)$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da85923",
      "metadata": {
        "id": "8da85923"
      },
      "source": [
        "State Creation\n",
        "\n",
        "+ This creates a grid-world-esque setup, where the team \"teleports\" to different cells depending on enemy intent, team and enemy HPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83287173",
      "metadata": {
        "id": "83287173"
      },
      "outputs": [],
      "source": [
        "H = TeamMaxHP + 1  # All possible Team HP values\n",
        "W = EnemyMaxHP + 1  # All possible Enemy HP values\n",
        "\n",
        "# A flattened cuboid (len(Intent)(2) * H(11) * W(11))\n",
        "# Or, two squares, one on top of another\n",
        "# top one, S[0,:,:] has numbers corresp to 'no intent of attack' ~ [0,120] (in this example)\n",
        "# bottom one, S[1,:,:] has the ones that indicate 'attack intent' ~ [121,241] (in this example)\n",
        "\n",
        "S               = jnp.arange(2 * H * W)\n",
        "action_profiles = jnp.array(list(product(ACTIONS, repeat=3)))  # All possible joint actions (3 players)\n",
        "A               = jnp.arange(len(action_profiles))                        # Action space (set of indices into Actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fff910",
      "metadata": {
        "id": "90fff910"
      },
      "source": [
        "Role Policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "43727289",
      "metadata": {
        "id": "43727289"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def get_intent_and_hps_from_state(s):\n",
        "    i = s // (H * W) # to which 'square' (see above) does s belong to?\n",
        "    rem = s % (H * W)\n",
        "\n",
        "    team_hp = rem // W\n",
        "    enemy_hp = rem % W\n",
        "    return i, team_hp, enemy_hp\n",
        "\n",
        "@jax.jit\n",
        "def fighter_policy(action):\n",
        "    return jnp.where(\n",
        "        action == ATTACK,\n",
        "        1.0 - EPSILON,\n",
        "        EPSILON / (len(ACTIONS) - 1),\n",
        "    )\n",
        "\n",
        "@jax.jit\n",
        "def defender_policy(action, intent):\n",
        "    # If opponent intends to attack → defend\n",
        "    # Else → attack\n",
        "    preferred_action = jnp.where(\n",
        "        intent == ENEMY_ATTACK_INTENT,\n",
        "        DEFEND,\n",
        "        ATTACK,\n",
        "    )\n",
        "\n",
        "    return jnp.where(\n",
        "        action == preferred_action,\n",
        "        1.0 - EPSILON,\n",
        "        EPSILON / (len(ACTIONS) - 1),\n",
        "    )\n",
        "\n",
        "@jax.jit\n",
        "def healer_policy(action, team_hp):\n",
        "    # If team HP is low → heal\n",
        "    # Else → attack\n",
        "    preferred_action = jnp.where(\n",
        "        team_hp < (0.5 * TeamMaxHP),\n",
        "        HEAL,\n",
        "        ATTACK,\n",
        "    )\n",
        "\n",
        "    return jnp.where(\n",
        "        action == preferred_action,\n",
        "        1.0 - EPSILON,\n",
        "        EPSILON / (len(ACTIONS) - 1),\n",
        "    )\n",
        "\n",
        "@jax.jit\n",
        "def choose_policy(role, action, intent, team_hp):\n",
        "    return jnp.where(\n",
        "        role == ATTACKER,\n",
        "        fighter_policy(action),\n",
        "        jnp.where(\n",
        "            role == DEFENDER,\n",
        "            defender_policy(action, intent),\n",
        "            healer_policy(action, team_hp),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "@jax.jit\n",
        "def action_profile_prob(s, a, r0, r1, r2):\n",
        "    intent, team_hp, _  = get_intent_and_hps_from_state(s)\n",
        "    a = action_profiles[a]  # decode joint action\n",
        "    # r = role_combos[r]      # decode role profile\n",
        "\n",
        "    prob = jnp.ones(3)\n",
        "    prob = prob.at[0].set(choose_policy(r0, a[0], intent, team_hp))\n",
        "    prob = prob.at[1].set(choose_policy(r1, a[1], intent, team_hp))\n",
        "    prob = prob.at[2].set(choose_policy(r2, a[2], intent, team_hp))\n",
        "    prob = jnp.prod(prob)\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65377b51",
      "metadata": {
        "id": "65377b51"
      },
      "source": [
        "Transition Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "910fa159",
      "metadata": {
        "id": "910fa159"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def T(s, a, s_, r0, r1, r2):\n",
        "    \"\"\" Transition function T(s, a, s_) = P(s_ | s, a) \"\"\"\n",
        "\n",
        "    # extract HPs and intent from s, current state\n",
        "    prob_act = action_profile_prob(s, a, r0, r1, r2)\n",
        "    a = action_profiles[a]  # decode joint action\n",
        "\n",
        "    i, team_hp, enemy_hp = get_intent_and_hps_from_state(s)\n",
        "\n",
        "    # Calculate Total Attack, Max Defense, Total Heal\n",
        "\n",
        "    total_attack = jnp.sum(jnp.where((a == ATTACK), player_stats[:, ATTACK],0))\n",
        "    max_defense = jnp.max(jnp.where((a == DEFEND), player_stats[:, DEFEND],0))\n",
        "    total_heal = jnp.sum(jnp.where((a == HEAL), player_stats[:, HEAL],0))\n",
        "\n",
        "    # Update HPs\n",
        "    new_enemy_hp = jnp.maximum(0, enemy_hp - total_attack)\n",
        "\n",
        "    # No damage taken if enemy does not attack\n",
        "    damage_incoming = jnp.where(\n",
        "        i == ENEMY_ATTACK_INTENT,\n",
        "        jnp.maximum(0, boss_damage - max_defense),\n",
        "        0\n",
        "    )\n",
        "\n",
        "    new_team_hp = team_hp - damage_incoming + total_heal\n",
        "    new_team_hp = jnp.maximum(0, jnp.minimum(TeamMaxHP, new_team_hp))\n",
        "\n",
        "    # extract HPs and intent from s_, future state to compare and decide transition probability\n",
        "    s_intent, s_team_hp, s_enemy_hp  = get_intent_and_hps_from_state(s_)\n",
        "\n",
        "    prob =  ((new_team_hp == s_team_hp) & (new_enemy_hp == s_enemy_hp)) * \\\n",
        "                (\n",
        "                    (\n",
        "                        ((1 - EnemyAttackProb) * (s_intent == ENEMY_NO_ATTACK_INTENT)) +   # enemy does not attack, 1 - p\n",
        "                        (EnemyAttackProb * (s_intent == ENEMY_ATTACK_INTENT))             # enemy attacks, p\n",
        "                    )\n",
        "                ) * prob_act\n",
        "\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe70ad9",
      "metadata": {
        "id": "2fe70ad9"
      },
      "source": [
        "Reward Function, termination check \\\n",
        "\\\n",
        "**NOTE:** $R: S \\rightarrow \\mathbb{R}$,    State reward function, $100 \\times (1 - T/H)$ for dead enemy, alive team. $T$ is the number of turns it took to beat the enemy; else, 0. \\\n",
        "\\\n",
        "The code, however, computes $100 \\times (1 - T/H)$. This is because the memo recurses *back* in time.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "04672ee2",
      "metadata": {
        "id": "04672ee2"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def R(s, t):\n",
        "    _, team_hp, enemy_hp  = get_intent_and_hps_from_state(s)\n",
        "    return ((team_hp != 0) & (enemy_hp == 0)) * 100 * (t/HORIZON)\n",
        "\n",
        "@jax.jit\n",
        "def is_terminal(s):\n",
        "    _, team_hp, enemy_hp = get_intent_and_hps_from_state(s)\n",
        "    return jnp.logical_or(team_hp == 0, enemy_hp == 0) # if either entity dies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "620e0583",
      "metadata": {
        "id": "620e0583"
      },
      "source": [
        "State-Value Function $V(s)$ (iterating over all role combos for parallel processing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "SDe7ho_CVMw6",
      "metadata": {
        "id": "SDe7ho_CVMw6"
      },
      "outputs": [],
      "source": [
        "@cache\n",
        "@memo\n",
        "def V[s:S](t, r0, r1, r2):\n",
        "  observer: knows(s)\n",
        "  observer: chooses(a in A, wpp = action_profile_prob(s, a, r0, r1, r2))\n",
        "  observer: draws(s_ in S, wpp = T(s, a, s_, r0, r1, r2))\n",
        "  return E[\n",
        "        R(s, t) + \n",
        "            (\n",
        "                0.0 if t == 0 else             # recursion depth reached\n",
        "                0.0 if is_terminal(s) else     # terminal state (either entity dead)\n",
        "                V[observer.s_](t - 1, r0, r1, r2)       # continue to recurse\n",
        "            ) \n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "jmXjhBKlWGxn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmXjhBKlWGxn",
        "outputId": "21096389-0c69-4083-a507-9c40ef7ed738"
      },
      "outputs": [],
      "source": [
        "V(0, *role_assignment)\n",
        "values = V(HORIZON, *role_assignment).reshape((2, H, W))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8a40d467",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Role Assignment                               | No Init Attack       | Init Attack         \n",
            "------------------------------------------------------------------------------------------\n",
            "('ATTACKER', 'ATTACKER', 'HEALER')            : 40.0000               | 30.0000\n",
            "('ATTACKER', 'HEALER', 'ATTACKER')            : 40.0000               | 30.0000\n",
            "('ATTACKER', 'HEALER', 'HEALER')              : 40.0000               | 30.0000\n",
            "('HEALER', 'ATTACKER', 'ATTACKER')            : 40.0000               | 30.0000\n",
            "('HEALER', 'ATTACKER', 'HEALER')              : 40.0000               | 30.0000\n",
            "('HEALER', 'HEALER', 'ATTACKER')              : 40.0000               | 30.0000\n",
            "('HEALER', 'HEALER', 'HEALER')                : 30.0000               | 20.0000\n",
            "('ATTACKER', 'ATTACKER', 'DEFENDER')          : 20.0000               | 20.0000\n",
            "('ATTACKER', 'DEFENDER', 'ATTACKER')          : 20.0000               | 20.0000\n",
            "('ATTACKER', 'DEFENDER', 'HEALER')            : 20.0000               | 20.0000\n",
            "('ATTACKER', 'HEALER', 'DEFENDER')            : 20.0000               | 20.0000\n",
            "('DEFENDER', 'ATTACKER', 'ATTACKER')          : 20.0000               | 20.0000\n",
            "('DEFENDER', 'ATTACKER', 'HEALER')            : 20.0000               | 20.0000\n",
            "('DEFENDER', 'HEALER', 'ATTACKER')            : 20.0000               | 20.0000\n",
            "('DEFENDER', 'HEALER', 'HEALER')              : 20.0000               | 20.0000\n",
            "('HEALER', 'ATTACKER', 'DEFENDER')            : 20.0000               | 20.0000\n",
            "('HEALER', 'DEFENDER', 'ATTACKER')            : 20.0000               | 20.0000\n",
            "('HEALER', 'DEFENDER', 'HEALER')              : 20.0000               | 20.0000\n",
            "('HEALER', 'HEALER', 'DEFENDER')              : 20.0000               | 20.0000\n",
            "('ATTACKER', 'ATTACKER', 'ATTACKER')          : 0.0000               | 0.0000\n",
            "('ATTACKER', 'DEFENDER', 'DEFENDER')          : 0.0000               | 0.0000\n",
            "('DEFENDER', 'ATTACKER', 'DEFENDER')          : 0.0000               | 0.0000\n",
            "('DEFENDER', 'DEFENDER', 'ATTACKER')          : 0.0000               | 0.0000\n",
            "('DEFENDER', 'DEFENDER', 'DEFENDER')          : 0.0000               | 0.0000\n",
            "('DEFENDER', 'DEFENDER', 'HEALER')            : 0.0000               | 0.0000\n",
            "('DEFENDER', 'HEALER', 'DEFENDER')            : 0.0000               | 0.0000\n",
            "('HEALER', 'DEFENDER', 'DEFENDER')            : 0.0000               | 0.0000\n"
          ]
        }
      ],
      "source": [
        "ROLE_MAP = {0: 'ATTACKER', 1: 'DEFENDER', 2: 'HEALER'}\n",
        "\n",
        "value_dict = {}\n",
        "\n",
        "roles_to_values = {}\n",
        "\n",
        "for roles in ROLE_COMBOS:\n",
        "\n",
        "    values = V(0, *roles)\n",
        "    values = V(HORIZON, *roles)\n",
        "    values = values.reshape((2, H, W))\n",
        "\n",
        "    start_values = values[:, -1, -1].tolist()\n",
        "\n",
        "    role_names = tuple(ROLE_MAP[r] for r in roles)\n",
        "    value_dict[role_names] = start_values\n",
        "\n",
        "    roles_to_values[roles] = values\n",
        "\n",
        "sorted_strategies = sorted(value_dict.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "print(f\"{'Role Assignment':<45} | {'No Init Attack':<20} | {'Init Attack':<20}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "for strategy, value in sorted_strategies:\n",
        "\n",
        "    formatted_roles = [f\"'{role}'\" for role in strategy]\n",
        "    strategy_str = \"(\" + \", \".join(formatted_roles) + \")\"\n",
        "\n",
        "    val_no_attack = value[0]\n",
        "    val_attack = value[1]\n",
        "\n",
        "    print(f\"{strategy_str:<45} : {val_no_attack:.4f}{'':<14} | {val_attack:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b196fccb",
      "metadata": {},
      "source": [
        "# Part 2: Simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee492e0a",
      "metadata": {},
      "source": [
        "memo model for role inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8b52479e",
      "metadata": {},
      "outputs": [],
      "source": [
        "@memo\n",
        "def role_inference[r0 : ROLES, r1 : ROLES, r2 : ROLES](role_prior:... , obs_a0, obs_a1, obs_a2, s):\n",
        "    observer: knows(r0, r1, r2) # Push array axis variables into observer's frame\n",
        "    observer: thinks[\n",
        "        team: assigned(r0 in ROLES, r1 in ROLES, r2 in ROLES, wpp=get_element(role_prior, r0, r1, r2)), # Assign roles to each player\n",
        "        team: chooses(a0 in ACTIONS, wpp=role_policy(r0, a0, s)), # Choose player 0's action (a0) according to their role (r0)\n",
        "        team: chooses(a1 in ACTIONS, wpp=role_policy(r1, a1, s)), # Choose player 1's action (a1) according to their role (r1)\n",
        "        team: chooses(a2 in ACTIONS, wpp=role_policy(r2, a2, s))  # Choose player 2's action (a2) according to their role (r2)\n",
        "    ]\n",
        "    observer: observes_that [team.a0 == obs_a0] # Observe player 0's action\n",
        "    observer: observes_that [team.a1 == obs_a1] # Observe player 1's action\n",
        "    observer: observes_that [team.a2 == obs_a2] # Observe player 2's action\n",
        "    return observer[Pr[r0 == team.r0 and r1 == team.r1 and r2 == team.r2]]\n",
        "\n",
        "# Due to some of memo's limitations, we also need to introduce a helper function that extracts an element from a (3D) array:\n",
        "@jax.jit\n",
        "def get_element(array, i0, i1, i2):\n",
        "    return array[i0, i1, i2]\n",
        "\n",
        "def role_policy(role, action, state):\n",
        "    intent, team_hp, _ = get_intent_and_hps_from_state(state)\n",
        "    return choose_policy(role, action, intent, team_hp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e46a1e5f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+-----------+---------------------+\n",
            "| r0: ROLES | r1: ROLES | r2: ROLES | role_inference      |\n",
            "+-----------+-----------+-----------+---------------------+\n",
            "| 0         | 0         | 0         | 0.0                 |\n",
            "| 0         | 0         | 1         | 0.0                 |\n",
            "| 0         | 0         | 2         | 0.0                 |\n",
            "| 0         | 1         | 0         | 0.1666666567325592  |\n",
            "| 0         | 1         | 1         | 0.1666666567325592  |\n",
            "| 0         | 1         | 2         | 0.1666666567325592  |\n",
            "| 0         | 2         | 0         | 0.0                 |\n",
            "| 0         | 2         | 1         | 0.0                 |\n",
            "| 0         | 2         | 2         | 0.0                 |\n",
            "| 1         | 0         | 0         | 0.0                 |\n",
            "| 1         | 0         | 1         | 0.0                 |\n",
            "| 1         | 0         | 2         | 0.0                 |\n",
            "| 1         | 1         | 0         | 0.0                 |\n",
            "| 1         | 1         | 1         | 0.0                 |\n",
            "| 1         | 1         | 2         | 0.0                 |\n",
            "| 1         | 2         | 0         | 0.0                 |\n",
            "| 1         | 2         | 1         | 0.0                 |\n",
            "| 1         | 2         | 2         | 0.0                 |\n",
            "| 2         | 0         | 0         | 0.0                 |\n",
            "| 2         | 0         | 1         | 0.0                 |\n",
            "| 2         | 0         | 2         | 0.0                 |\n",
            "| 2         | 1         | 0         | 0.1666666567325592  |\n",
            "| 2         | 1         | 1         | 0.1666666567325592  |\n",
            "| 2         | 1         | 2         | 0.1666666567325592  |\n",
            "| 2         | 2         | 0         | 0.0                 |\n",
            "| 2         | 2         | 1         | 0.0                 |\n",
            "| 2         | 2         | 2         | 0.0                 |\n",
            "+-----------+-----------+-----------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "role_prior = jnp.ones((3, 3, 3))\n",
        "actions = [ATTACK, DEFEND, HEAL]\n",
        "role_probs = role_inference(role_prior, *actions, 2 * H * W - 1, print_table=True)\n",
        "role_prior = jnp.ones((3, 3, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c48f6f2c",
      "metadata": {},
      "source": [
        "Softmax sampling of roles\n",
        "\n",
        "$r_i \\sim Softmax \\left( \\mathbb{E}_{r \\sim \\text{role\\_prior}(r_i, r_{-i})} \\left[ V^{r}(s)\\right]\\right)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "39c4f6df",
      "metadata": {},
      "outputs": [],
      "source": [
        "def softmax_dist_over_roles(i, s):\n",
        "\n",
        "    global ROLES\n",
        "    other_agents = [a for a in range(3) if a != i]\n",
        "    intent, team_hp, enemy_hp = get_intent_and_hps_from_state(s)\n",
        "\n",
        "    other_probs = jnp.sum(role_prior, axis=i)\n",
        "    other_probs = other_probs / jnp.sum(other_probs)\n",
        "\n",
        "    expected_values = jnp.zeros(3)\n",
        "\n",
        "    for r_i in ROLES:\n",
        "        ev = 0.0\n",
        "        for r_j in ROLES:\n",
        "            for r_k in ROLES:\n",
        "\n",
        "                curr_roles = [None] * 3\n",
        "                curr_roles[i] = r_i\n",
        "                curr_roles[other_agents[0]] = r_j\n",
        "                curr_roles[other_agents[1]] = r_k\n",
        "\n",
        "                weight = other_probs[r_j, r_k]\n",
        "                ev += weight * roles_to_values[tuple(curr_roles)][intent, team_hp, enemy_hp]\n",
        "\n",
        "        expected_values = expected_values.at[r_i].set(ev)\n",
        "\n",
        "    return jax.nn.softmax(expected_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d644a494",
      "metadata": {},
      "source": [
        "Based on role policies defined before, chose action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c90d8221",
      "metadata": {},
      "outputs": [],
      "source": [
        "def choose_action(role, intent, team_hp, key):\n",
        "    # Compute action probabilities for this role\n",
        "    probs = jnp.array([\n",
        "        choose_policy(role, ATTACK, intent, team_hp),\n",
        "        choose_policy(role, DEFEND, intent, team_hp),\n",
        "        choose_policy(role, HEAL, intent, team_hp),\n",
        "    ])\n",
        "\n",
        "    # (Optional but safe) normalize in case of numerical drift\n",
        "    probs = probs / jnp.sum(probs)\n",
        "\n",
        "    action = jax.random.choice(key, len(ACTIONS), p=probs)\n",
        "    return action\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edfe8007",
      "metadata": {},
      "source": [
        "Change game state variables when actions occur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "65a985d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def game_step(intent, team_hp, enemy_hp, action_profile, key):\n",
        "\n",
        "    total_attack = jnp.sum(jnp.where((action_profile == ATTACK), player_stats[:, ATTACK],0))\n",
        "    max_defense = jnp.max(jnp.where((action_profile == DEFEND), player_stats[:, DEFEND],0))\n",
        "    total_heal = jnp.sum(jnp.where((action_profile == HEAL), player_stats[:, HEAL],0))\n",
        "\n",
        "    new_enemy_hp = jnp.maximum(0, enemy_hp - total_attack)\n",
        "\n",
        "    damage_incoming = jnp.where(intent == ENEMY_ATTACK_INTENT, jnp.maximum(0, boss_damage - max_defense), 0)\n",
        "\n",
        "    new_team_hp = team_hp - damage_incoming + total_heal\n",
        "    new_team_hp = jnp.maximum(0, jnp.minimum(TeamMaxHP, new_team_hp))\n",
        "\n",
        "    intent_key, _ = jax.random.split(key)\n",
        "    new_intent = jnp.where(jax.random.uniform(intent_key) < EnemyAttackProb, \n",
        "                           ENEMY_ATTACK_INTENT, ENEMY_NO_ATTACK_INTENT)\n",
        "\n",
        "    return new_intent, new_team_hp, new_enemy_hp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1fed589f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_game(n_steps, initial_state):\n",
        "    \n",
        "    global role_prior \n",
        "    key = jax.random.PRNGKey(42) \n",
        "    intent, team_hp, enemy_hp = get_intent_and_hps_from_state(initial_state)\n",
        "    \n",
        "    state_history, role_history, action_history = [], [], []\n",
        "    belief_history = [role_prior] \n",
        "    \n",
        "    # Initialize roles for the first round\n",
        "    current_roles = [0, 0, 0] \n",
        "\n",
        "    for t in range(n_steps):\n",
        "        current_state = intent * (H * W) + team_hp * W + enemy_hp\n",
        "        state_history.append(current_state)\n",
        "        \n",
        "        if is_terminal(current_state):\n",
        "            break\n",
        "            \n",
        "        # 1. Sample Roles ONLY every 2 turns\n",
        "        if t % 2 == 0:\n",
        "            new_roles = current_roles[:]\n",
        "            i = 0   # only player 0 is doing the sampling, rest are stubborn\n",
        "            key, subkey = jax.random.split(key)\n",
        "            probs = softmax_dist_over_roles(i, current_state)\n",
        "            role = jax.random.categorical(subkey, jnp.log(probs))\n",
        "            new_roles[0] = int(role)\n",
        "            current_roles = new_roles\n",
        "        \n",
        "        # Always append the 'active' roles for this turn to the history\n",
        "        role_history.append(list(current_roles))\n",
        "\n",
        "        # 2. Choose Actions\n",
        "        current_actions = []\n",
        "        for i in range(3):\n",
        "            key, subkey = jax.random.split(key)\n",
        "            action = choose_action(current_roles[i], intent, team_hp, key=subkey)\n",
        "            current_actions.append(int(action))\n",
        "        action_history.append(current_actions)\n",
        "\n",
        "        # 3. Update Role Beliefs (Bayesian Inference)\n",
        "        role_prior = role_inference(\n",
        "            role_prior, \n",
        "            current_actions[0], current_actions[1], current_actions[2], \n",
        "            current_state\n",
        "        )\n",
        "        belief_history.append(role_prior)\n",
        "\n",
        "        # 4. Advance Environment\n",
        "        key, subkey = jax.random.split(key)\n",
        "        intent, team_hp, enemy_hp = game_step(intent, team_hp, enemy_hp, jnp.array(current_actions), key=subkey)\n",
        "\n",
        "    # Capture final state\n",
        "    final_state = intent * (H * W) + team_hp * W + enemy_hp\n",
        "    if not is_terminal(state_history[-1]):\n",
        "        state_history.append(final_state)\n",
        "\n",
        "    return state_history, role_history, action_history, belief_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2ad27532",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_state_from_intent_and_hps(intent, team_hp, enemy_hp):\n",
        "    return intent * (H * W) + team_hp * W + enemy_hp\n",
        "\n",
        "initial_state_idx = get_state_from_intent_and_hps(ENEMY_ATTACK_INTENT, TeamMaxHP, EnemyMaxHP)\n",
        "\n",
        "states, roles, actions, beliefs = simulate_game(n_steps=20, initial_state=initial_state_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "175d7bd6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step  | Intent     | Team HP  | Enemy HP | Roles (P0, P1, P2)     | Actions         | Enemy Atk?\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "0     | ATTACK     | 10       | 31       | (HEL, ATK, ATK)        | (ATK, ATK, ATK) | YES\n",
            "1     | ATTACK     | 8        | 25       | (HEL, ATK, ATK)        | (ATK, ATK, ATK) | YES\n",
            "2     | ATTACK     | 6        | 19       | (DEF, ATK, ATK)        | (DEF, ATK, ATK) | YES\n",
            "3     | ATTACK     | 6        | 15       | (DEF, ATK, ATK)        | (DEF, ATK, ATK) | YES\n",
            "4     | ATTACK     | 6        | 11       | (ATK, ATK, ATK)        | (ATK, ATK, ATK) | YES\n",
            "5     | ATTACK     | 4        | 5        | (ATK, ATK, ATK)        | (ATK, ATK, ATK) | YES\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "FINAL | -          | 2        | 0        | -                      | -               | GAME OVER\n"
          ]
        }
      ],
      "source": [
        "# Table Header\n",
        "print(f\"{'Step':<5} | {'Intent':<10} | {'Team HP':<8} | {'Enemy HP':<8} | {'Roles (P0, P1, P2)':<22} | {'Actions':<15} | {'Enemy Atk?'}\")\n",
        "print(\"-\" * 110)\n",
        "\n",
        "# Map integers to names for readability\n",
        "role_names = {0: \"ATK\", 1: \"DEF\", 2: \"HEL\"}\n",
        "action_names = {0: \"ATK\", 1: \"DEF\", 2: \"HEL\"}\n",
        "\n",
        "for t in range(len(actions)):\n",
        "    # Get state info at the START of the round\n",
        "    intent_val, team_hp, enemy_hp = get_intent_and_hps_from_state(states[t])\n",
        "    \n",
        "    # Format Roles and Actions for this step\n",
        "    step_roles = f\"({role_names[roles[t][0]]}, {role_names[roles[t][1]]}, {role_names[roles[t][2]]})\"\n",
        "    step_actions = f\"({action_names[actions[t][0]]}, {action_names[actions[t][1]]}, {action_names[actions[t][2]]})\"\n",
        "    \n",
        "    # Determine enemy behavior\n",
        "    did_attack = \"YES\" if intent_val == ENEMY_ATTACK_INTENT else \"NO\"\n",
        "    intent_str = \"ATTACK\" if intent_val == ENEMY_ATTACK_INTENT else \"WAIT\"\n",
        "    \n",
        "    print(f\"{t:<5} | {intent_str:<10} | {team_hp:<8} | {enemy_hp:<8} | {step_roles:<22} | {step_actions:<15} | {did_attack}\")\n",
        "\n",
        "# Final termination row\n",
        "final_intent, final_team_hp, final_enemy_hp = get_intent_and_hps_from_state(states[-1])\n",
        "print(\"-\" * 110)\n",
        "print(f\"FINAL | {'-':<10} | {final_team_hp:<8} | {final_enemy_hp:<8} | {'-':<22} | {'-':<15} | GAME OVER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5b0f3d2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Belief Evolution (Probability of Role Combinations) ---\n",
            "\n",
            "Step 0 Beliefs:\n",
            "  (ATK, ATK, ATK): 1.0000\n",
            "  (ATK, ATK, DEF): 1.0000\n",
            "  (ATK, ATK, HEL): 1.0000\n",
            "  (ATK, DEF, ATK): 1.0000\n",
            "  (ATK, DEF, DEF): 1.0000\n",
            "  (ATK, DEF, HEL): 1.0000\n",
            "  (ATK, HEL, ATK): 1.0000\n",
            "  (ATK, HEL, DEF): 1.0000\n",
            "  (ATK, HEL, HEL): 1.0000\n",
            "  (DEF, ATK, ATK): 1.0000\n",
            "  (DEF, ATK, DEF): 1.0000\n",
            "  (DEF, ATK, HEL): 1.0000\n",
            "  (DEF, DEF, ATK): 1.0000\n",
            "  (DEF, DEF, DEF): 1.0000\n",
            "  (DEF, DEF, HEL): 1.0000\n",
            "  (DEF, HEL, ATK): 1.0000\n",
            "  (DEF, HEL, DEF): 1.0000\n",
            "  (DEF, HEL, HEL): 1.0000\n",
            "  (HEL, ATK, ATK): 1.0000\n",
            "  (HEL, ATK, DEF): 1.0000\n",
            "  (HEL, ATK, HEL): 1.0000\n",
            "  (HEL, DEF, ATK): 1.0000\n",
            "  (HEL, DEF, DEF): 1.0000\n",
            "  (HEL, DEF, HEL): 1.0000\n",
            "  (HEL, HEL, ATK): 1.0000\n",
            "  (HEL, HEL, DEF): 1.0000\n",
            "  (HEL, HEL, HEL): 1.0000\n",
            "\n",
            "Step 1 Beliefs:\n",
            "  (ATK, ATK, ATK): 0.1250\n",
            "  (ATK, ATK, HEL): 0.1250\n",
            "  (ATK, HEL, ATK): 0.1250\n",
            "  (ATK, HEL, HEL): 0.1250\n",
            "  (HEL, ATK, ATK): 0.1250\n",
            "  (HEL, ATK, HEL): 0.1250\n",
            "  (HEL, HEL, ATK): 0.1250\n",
            "  (HEL, HEL, HEL): 0.1250\n",
            "  (ATK, ATK, DEF): 0.0000\n",
            "  (ATK, DEF, ATK): 0.0000\n",
            "  (ATK, DEF, HEL): 0.0000\n",
            "  (ATK, HEL, DEF): 0.0000\n",
            "  (DEF, ATK, ATK): 0.0000\n",
            "  (DEF, ATK, HEL): 0.0000\n",
            "  (DEF, HEL, ATK): 0.0000\n",
            "  (DEF, HEL, HEL): 0.0000\n",
            "  (HEL, ATK, DEF): 0.0000\n",
            "  (HEL, DEF, ATK): 0.0000\n",
            "  (HEL, DEF, HEL): 0.0000\n",
            "  (HEL, HEL, DEF): 0.0000\n",
            "  (ATK, DEF, DEF): 0.0000\n",
            "  (DEF, ATK, DEF): 0.0000\n",
            "  (DEF, DEF, ATK): 0.0000\n",
            "  (DEF, DEF, HEL): 0.0000\n",
            "  (DEF, HEL, DEF): 0.0000\n",
            "  (HEL, DEF, DEF): 0.0000\n",
            "  (DEF, DEF, DEF): 0.0000\n",
            "\n",
            "Step 2 Beliefs:\n",
            "  (ATK, ATK, ATK): 0.1250\n",
            "  (ATK, ATK, HEL): 0.1250\n",
            "  (ATK, HEL, ATK): 0.1250\n",
            "  (ATK, HEL, HEL): 0.1250\n",
            "  (HEL, ATK, ATK): 0.1250\n",
            "  (HEL, ATK, HEL): 0.1250\n",
            "  (HEL, HEL, ATK): 0.1250\n",
            "  (HEL, HEL, HEL): 0.1250\n",
            "  (ATK, ATK, DEF): 0.0000\n",
            "  (ATK, DEF, ATK): 0.0000\n",
            "  (ATK, DEF, HEL): 0.0000\n",
            "  (ATK, HEL, DEF): 0.0000\n",
            "  (DEF, ATK, ATK): 0.0000\n",
            "  (DEF, ATK, HEL): 0.0000\n",
            "  (DEF, HEL, ATK): 0.0000\n",
            "  (DEF, HEL, HEL): 0.0000\n",
            "  (HEL, ATK, DEF): 0.0000\n",
            "  (HEL, DEF, ATK): 0.0000\n",
            "  (HEL, DEF, HEL): 0.0000\n",
            "  (HEL, HEL, DEF): 0.0000\n",
            "  (ATK, DEF, DEF): 0.0000\n",
            "  (DEF, ATK, DEF): 0.0000\n",
            "  (DEF, DEF, ATK): 0.0000\n",
            "  (DEF, DEF, DEF): 0.0000\n",
            "  (DEF, DEF, HEL): 0.0000\n",
            "  (DEF, HEL, DEF): 0.0000\n",
            "  (HEL, DEF, DEF): 0.0000\n",
            "\n",
            "Step 3 Beliefs:\n",
            "  (ATK, ATK, ATK): 0.1250\n",
            "  (ATK, ATK, HEL): 0.1250\n",
            "  (ATK, HEL, ATK): 0.1250\n",
            "  (ATK, HEL, HEL): 0.1250\n",
            "  (HEL, ATK, ATK): 0.1250\n",
            "  (HEL, ATK, HEL): 0.1250\n",
            "  (HEL, HEL, ATK): 0.1250\n",
            "  (HEL, HEL, HEL): 0.1250\n",
            "  (DEF, ATK, ATK): 0.0000\n",
            "  (DEF, ATK, HEL): 0.0000\n",
            "  (DEF, HEL, ATK): 0.0000\n",
            "  (DEF, HEL, HEL): 0.0000\n",
            "  (ATK, ATK, DEF): 0.0000\n",
            "  (ATK, DEF, ATK): 0.0000\n",
            "  (ATK, DEF, DEF): 0.0000\n",
            "  (ATK, DEF, HEL): 0.0000\n",
            "  (ATK, HEL, DEF): 0.0000\n",
            "  (DEF, ATK, DEF): 0.0000\n",
            "  (DEF, DEF, ATK): 0.0000\n",
            "  (DEF, DEF, DEF): 0.0000\n",
            "  (DEF, DEF, HEL): 0.0000\n",
            "  (DEF, HEL, DEF): 0.0000\n",
            "  (HEL, ATK, DEF): 0.0000\n",
            "  (HEL, DEF, ATK): 0.0000\n",
            "  (HEL, DEF, DEF): 0.0000\n",
            "  (HEL, DEF, HEL): 0.0000\n",
            "  (HEL, HEL, DEF): 0.0000\n",
            "\n",
            "Step 4 Beliefs:\n",
            "  (ATK, ATK, ATK): 0.0833\n",
            "  (ATK, ATK, HEL): 0.0833\n",
            "  (ATK, HEL, ATK): 0.0833\n",
            "  (ATK, HEL, HEL): 0.0833\n",
            "  (HEL, ATK, ATK): 0.0833\n",
            "  (HEL, ATK, HEL): 0.0833\n",
            "  (HEL, HEL, ATK): 0.0833\n",
            "  (HEL, HEL, HEL): 0.0833\n",
            "  (DEF, ATK, ATK): 0.0833\n",
            "  (DEF, ATK, HEL): 0.0833\n",
            "  (DEF, HEL, ATK): 0.0833\n",
            "  (DEF, HEL, HEL): 0.0833\n",
            "  (ATK, ATK, DEF): 0.0000\n",
            "  (ATK, DEF, ATK): 0.0000\n",
            "  (ATK, DEF, DEF): 0.0000\n",
            "  (ATK, DEF, HEL): 0.0000\n",
            "  (ATK, HEL, DEF): 0.0000\n",
            "  (DEF, ATK, DEF): 0.0000\n",
            "  (DEF, DEF, ATK): 0.0000\n",
            "  (DEF, DEF, DEF): 0.0000\n",
            "  (DEF, DEF, HEL): 0.0000\n",
            "  (DEF, HEL, DEF): 0.0000\n",
            "  (HEL, ATK, DEF): 0.0000\n",
            "  (HEL, DEF, ATK): 0.0000\n",
            "  (HEL, DEF, DEF): 0.0000\n",
            "  (HEL, DEF, HEL): 0.0000\n",
            "  (HEL, HEL, DEF): 0.0000\n",
            "\n",
            "Step 5 Beliefs:\n",
            "  (ATK, ATK, ATK): 0.1250\n",
            "  (ATK, ATK, HEL): 0.1250\n",
            "  (ATK, HEL, ATK): 0.1250\n",
            "  (ATK, HEL, HEL): 0.1250\n",
            "  (HEL, ATK, ATK): 0.1250\n",
            "  (HEL, ATK, HEL): 0.1250\n",
            "  (HEL, HEL, ATK): 0.1250\n",
            "  (HEL, HEL, HEL): 0.1250\n",
            "  (DEF, ATK, ATK): 0.0000\n",
            "  (DEF, ATK, HEL): 0.0000\n",
            "  (DEF, HEL, ATK): 0.0000\n",
            "  (DEF, HEL, HEL): 0.0000\n",
            "  (ATK, ATK, DEF): 0.0000\n",
            "  (ATK, DEF, ATK): 0.0000\n",
            "  (ATK, DEF, DEF): 0.0000\n",
            "  (ATK, DEF, HEL): 0.0000\n",
            "  (ATK, HEL, DEF): 0.0000\n",
            "  (DEF, ATK, DEF): 0.0000\n",
            "  (DEF, DEF, ATK): 0.0000\n",
            "  (DEF, DEF, DEF): 0.0000\n",
            "  (DEF, DEF, HEL): 0.0000\n",
            "  (DEF, HEL, DEF): 0.0000\n",
            "  (HEL, ATK, DEF): 0.0000\n",
            "  (HEL, DEF, ATK): 0.0000\n",
            "  (HEL, DEF, DEF): 0.0000\n",
            "  (HEL, DEF, HEL): 0.0000\n",
            "  (HEL, HEL, DEF): 0.0000\n",
            "\n",
            "Step 6 Beliefs:\n",
            "  (ATK, ATK, ATK): 1.0000\n",
            "  (ATK, ATK, HEL): 0.0000\n",
            "  (ATK, HEL, ATK): 0.0000\n",
            "  (HEL, ATK, ATK): 0.0000\n",
            "  (ATK, HEL, HEL): 0.0000\n",
            "  (HEL, ATK, HEL): 0.0000\n",
            "  (HEL, HEL, ATK): 0.0000\n",
            "  (DEF, ATK, ATK): 0.0000\n",
            "  (HEL, HEL, HEL): 0.0000\n",
            "  (DEF, ATK, HEL): 0.0000\n",
            "  (DEF, HEL, ATK): 0.0000\n",
            "  (ATK, ATK, DEF): 0.0000\n",
            "  (ATK, DEF, ATK): 0.0000\n",
            "  (ATK, DEF, DEF): 0.0000\n",
            "  (ATK, DEF, HEL): 0.0000\n",
            "  (ATK, HEL, DEF): 0.0000\n",
            "  (DEF, ATK, DEF): 0.0000\n",
            "  (DEF, DEF, ATK): 0.0000\n",
            "  (DEF, DEF, DEF): 0.0000\n",
            "  (DEF, DEF, HEL): 0.0000\n",
            "  (DEF, HEL, DEF): 0.0000\n",
            "  (DEF, HEL, HEL): 0.0000\n",
            "  (HEL, ATK, DEF): 0.0000\n",
            "  (HEL, DEF, ATK): 0.0000\n",
            "  (HEL, DEF, DEF): 0.0000\n",
            "  (HEL, DEF, HEL): 0.0000\n",
            "  (HEL, HEL, DEF): 0.0000\n"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "\n",
        "# Map indices to names\n",
        "ROLE_LABELS = {0: \"ATK\", 1: \"DEF\", 2: \"HEL\"}\n",
        "role_indices = list(product(range(3), repeat=3))\n",
        "\n",
        "print(\"\\n--- Belief Evolution (Probability of Role Combinations) ---\")\n",
        "\n",
        "for t, current_belief in enumerate(beliefs):\n",
        "    print(f\"\\nStep {t} Beliefs:\")\n",
        "    \n",
        "    # Sort combinations by probability to show the most likely ones first\n",
        "    probs = []\n",
        "    for r0, r1, r2 in role_indices:\n",
        "        prob = current_belief[r0, r1, r2]\n",
        "        combo_name = f\"({ROLE_LABELS[r0]}, {ROLE_LABELS[r1]}, {ROLE_LABELS[r2]})\"\n",
        "        probs.append((combo_name, prob))\n",
        "    \n",
        "    # Sort by probability descending\n",
        "    probs.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    for combo, p in probs:\n",
        "        print(f\"  {combo:<15}: {p:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "computational_model",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
